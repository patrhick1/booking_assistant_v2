# BookingAssistant - AI-Powered Email Response System

ğŸ¤– **Intelligent podcast booking assistant with real-time performance tracking and human feedback integration**

## ğŸ“š Table of Contents

- [ğŸš€ Replit Deployment (Recommended)](#-replit-deployment) - One-click deployment
- [ğŸ¯ Overview](#-overview) - System features and capabilities  
- [ğŸ—ï¸ Architecture](#-architecture) - Technical design
- [ğŸš€ Quick Start](#-quick-start) - Local development setup
- [ğŸ”§ Slack App Setup](#-slack-app-setup) - Integration configuration
- [ğŸ“Š Performance Dashboard](#-performance-dashboard) - Analytics and monitoring
- [ğŸ’¬ Slack Integration Features](#-slack-integration-features) - Interactive workflows
- [ğŸ§ª Testing & Development](#-testing--development) - Test suites and validation

## ğŸ¯ Overview

BookingAssistant is an advanced AI-powered email processing system that automatically classifies incoming emails, extracts relevant client documents, generates contextual draft replies, and provides comprehensive performance analytics. The system features interactive Slack integration for human oversight and real-time quality tracking.

### Key Features

ğŸ” **Smart Email Classification** - Automatically categorizes emails into response types  
ğŸ“ **Document Intelligence** - Extracts relevant client documents from Google Drive  
âœï¸ **Contextual Draft Generation** - Creates personalized responses using RAG  
ğŸ¯ **Strategic Rejection Handling** - Special pipeline for challenging rejections  
ğŸ’¬ **Interactive Slack Integration** - Rich feedback interface with quality ratings  
ğŸ“Š **Real-Time Analytics** - Comprehensive performance monitoring dashboard  
ğŸ“§ **Nylas Email Integration** - Unified email API for reading and creating drafts  

---

## ğŸ—ï¸ Architecture

### Core Pipeline (LangGraph-Based)

```
Email Input â†’ Classify â†’ Continue Check â†’ Pipeline Routing
                                            â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Standard Pipeline â”‚ 
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â†“
Query Generation â†’ Vector Retrieval â†’ Document Extraction
                                            â†“
              Draft Generation â†’ Draft Editing â†’ Slack Notification
                                            â†“
                                    Gmail Draft Creation
```

### Three-Phase Performance System

**Phase 1: Core Metrics Collection**
- Session tracking and node performance monitoring
- Classification accuracy and document extraction stats
- Draft quality metrics with template adherence scoring

**Phase 2: Real-Time Dashboard**
- Live analytics and visualization with Plotly
- Performance trends and quality insights
- System health monitoring and error tracking

**Phase 3: Human Feedback Integration**
- Interactive Slack messages with quality rating (1-5 stars)
- Approve/Edit/Reject workflow with feedback collection
- Edit distance calculation and quality improvement tracking

---

## ğŸš€ Quick Start

> **âš¡ REPLIT DEPLOYMENT (Recommended)**: For the fastest deployment, jump to the [Replit Deployment Section](#-replit-deployment) below.

### 1. Environment Setup

Create your `.env` file with the following variables:

```bash
# Neon PostgreSQL Database
PGDATABASE=neondb
PGUSER=neondb_owner
PGPASSWORD=your_neon_password
PGHOST=your-neon-host.aws.neon.tech
PGPORT=5432

# OpenAI API
OPENAI_API_KEY=your_openai_api_key

# Email Service - Nylas
NYLAS_API_KEY=your_nylas_api_key
NYLAS_GRANT_ID=your_nylas_grant_id
NYLAS_API_URI=https://api.us.nylas.com

# Google Drive (for document extraction)
GDRIVE_CLIENT_ROOT_FOLDER_ID=your_google_drive_folder_id
GOOGLE_APPLICATION_CREDENTIALS=src/service-account-key.json

# AstraDB Vector Database
ASTRA_DB_APPLICATION_TOKEN=your_astra_token
ASTRA_DB_API_ENDPOINT=your_astra_endpoint

# Slack Integration
SLACK_WEBHOOK_URL=your_slack_webhook_url
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token

# Attio CRM (Optional)
ATTIO_API_KEY=your_attio_api_key

# Testing Mode
TESTING_MODE=false
```

### 2. Database Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Setup Neon PostgreSQL database
python setup_complete_database.py

# Test database connection
python test_neon_connection.py
```

### 3. Start Services

```bash
# Run the unified application
python replit_unified_app.py
```

### 4. Access Interfaces

- **ğŸ“Š Performance Dashboard**: http://localhost:8080
- **ğŸ”— Slack Interactions**: http://localhost:8080/slack/interactions
- **ğŸ“š API Documentation**: http://localhost:8080/docs

---

## ğŸ”§ Slack App Setup

### Step 1: Create Slack App

1. Go to https://api.slack.com/apps
2. Click **"Create New App"** â†’ **"From scratch"**
3. Choose your workspace and app name (e.g., "BookingAssistant")

### Step 2: Configure Interactive Components

1. In your app settings, go to **"Interactive Components"**
2. Turn on **"Interactivity"**
3. Set **Request URL** to: `https://your-domain.com:8080/slack/interactions`
   - For local testing: `https://your-ngrok-url.ngrok.io/slack/interactions`
4. Click **"Save Changes"**

### Step 3: Set Up Incoming Webhooks

1. Go to **"Incoming Webhooks"**
2. Turn on **"Activate Incoming Webhooks"**
3. Click **"Add New Webhook to Workspace"**
4. Choose the channel where you want notifications
5. Copy the **Webhook URL** to your `.env` file as `SLACK_WEBHOOK_URL`

### Step 4: Configure Event Subscriptions (Optional)

1. Go to **"Event Subscriptions"**
2. Turn on **"Enable Events"**
3. Set **Request URL** to: `https://your-domain.com:8080/slack/events`
4. Subscribe to workspace events:
   - `message.channels` (for future message editing features)

### Step 5: Set OAuth Scopes

1. Go to **"OAuth & Permissions"**
2. Add the following **Bot Token Scopes**:
   - `incoming-webhook`
   - `chat:write`
   - `chat:write.public`
   - `commands` (if using slash commands)

### Step 6: Install App to Workspace

1. Go to **"Install App"**
2. Click **"Install to Workspace"**
3. Copy the **Bot User OAuth Token** to your `.env` file as `SLACK_BOT_TOKEN`

### Step 7: Test Integration

```bash
# Test the complete feedback system
python test_phase3_feedback.py
```

### Ngrok Setup for Local Testing

If testing locally, use ngrok to expose your endpoints:

```bash
# Install ngrok and expose port 8080
ngrok http 8080

# Use the https URL in your Slack app configuration
# Example: https://abc123.ngrok.io/slack/interactions
```

---

## ğŸ“Š Performance Dashboard

### Overview Metrics
- **Total Sessions**: Number of emails processed
- **Success Rate**: Percentage of successful processing
- **Average Processing Time**: Time per email analysis
- **Error Rate**: Recent processing failures

### Analytics Features
- **Processing Timeline**: Visual email processing history
- **Classification Distribution**: Email type breakdown with confidence scores
- **Document Extraction Stats**: Client matching and retrieval success rates
- **Draft Quality Metrics**: Template adherence and context usage analysis
- **Node Performance**: Individual component execution times and reliability

### Real-Time Features
- **Auto-refresh**: Updates every 30 seconds
- **Interactive Charts**: Hover details and time range selection
- **Session Monitoring**: Detailed view of individual processing sessions
- **Quality Trends**: Performance improvement tracking over time

---

## ğŸ’¬ Slack Integration Features

### Enhanced Interactive Messages

```
ğŸ“§ New Email Response Ready
From: client@example.com
Subject: Podcast Guest Request
Session: abc12345...

AI Analysis: [Generated analysis summary]

Generated Draft:
[Draft content preview...]

â­â­â­â­â­ Quality Rating Buttons (1-5 stars)

âœ… Approve & Send | âœï¸ Edit Draft | âŒ Reject

ğŸ“Š Attio Campaign | ğŸ“ Client Drive | ğŸ’¬ Add Feedback
```

### Feedback Collection
- **Quality Ratings**: 1-5 star rating system for draft quality
- **Action Tracking**: Approve/Edit/Reject decision logging
- **Edit Distance**: Measures modifications made to drafts
- **User Attribution**: Tracks who provided feedback and when
- **Session Linking**: Connects feedback to specific processing sessions

---

## ğŸ—ƒï¸ Database Schema

### Core Tables

**email_sessions** - Main processing session tracking
- Session ID, email hash, sender info, processing times, status

**node_executions** - Individual component performance
- Node name, execution time, success/failure, input/output data

**classification_results** - Email classification metrics
- Predicted label, confidence score, processing time

**document_extractions** - Google Drive integration stats
- Client matching, documents found, extraction success

**draft_generations** - Draft creation metrics
- Draft length, context usage, template adherence scores

**quality_feedback** - Human feedback integration
- Quality ratings, actions taken, edit tracking, user attribution

---

## ğŸ§ª Testing & Development

### Comprehensive Test Suite

```bash
# Test complete functionality (no Slack/Gmail)
python test_complete_functionality.py

# Test Phase 3 feedback integration
python test_phase3_feedback.py

# Test Neon database connectivity
python test_neon_connection.py

# Test specific scenarios
python "src/Test Case/test_multiple_scenarios.py"
```

### Development Mode

Set `TESTING_MODE=true` in your `.env` file to:
- Skip Slack notifications during development
- Skip Gmail draft creation
- Enable detailed logging
- Use test database sessions

--

## ğŸ“‹ Response Classifications

### Standard Types
- **A. Rejected** - "We do not allow guests"
- **B. Pay-to-Play** - "Paid slots only"
- **C. Accepted** - "We'd love to have you!"
- **D. Conditional** - "Interested - more info?"
- **E. Other/Unknown** - Unclassified responses

### Special Rejection Handling
- **Identity-based rejection** - Guest credentials questioned
- **Topic-based rejection** - Subject matter mismatch
- **Qualification-based rejection** - Experience requirements not met

Each type triggers specialized response strategies with strategic angles.

---

## ğŸ—ï¸ File Structure

```
BookingAssistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                      # Core LangGraph pipeline
â”‚   â”œâ”€â”€ prompts.py                   # LLM prompt templates
â”‚   â”œâ”€â”€ email_service.py             # Email fetching (Nylas)
â”‚   â”œâ”€â”€ nylas_email_service.py       # Nylas-specific operations
â”‚   â”œâ”€â”€ google_docs_service.py       # Google Drive integration
â”‚   â”œâ”€â”€ astradb_services.py          # Vector database operations
â”‚   â”œâ”€â”€ metrics_service.py           # Performance tracking service
â”‚   â”œâ”€â”€ dashboard_service.py         # Analytics backend
â”‚   â”œâ”€â”€ enhanced_slack_feedback_service.py # Enhanced Slack integration
â”‚   â”œâ”€â”€ utils.py                     # Utility functions
â”‚   â””â”€â”€ Test Case/                   # Automated testing suite
â”œâ”€â”€ replit_unified_app.py            # Unified FastAPI application
â”œâ”€â”€ setup_complete_database.py       # Database schema setup
â”œâ”€â”€ test_neon_connection.py          # Database connectivity test
â”œâ”€â”€ test_phase3_feedback.py          # Feedback integration test
â”œâ”€â”€ run_assistant.py                 # Main email processing script
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env.example                     # Environment template
â””â”€â”€ README.md                        # This file
```

---

## ğŸ¯ Quality Metrics

### Draft Quality Scoring
- **Template Adherence**: Measures compliance with response templates
- **Context Usage**: Tracks utilization of retrieved documents and email threads
- **Length Analysis**: Optimal response length for different email types
- **Placeholder Count**: Ensures complete information filling

### Performance Analytics
- **Processing Speed**: Node execution times and bottleneck identification
- **Success Rates**: Component reliability and error tracking
- **Classification Accuracy**: Model performance on email categorization
- **Document Matching**: Client folder identification and document retrieval rates

### Human Feedback Integration
- **Quality Trends**: Improvement patterns over time
- **User Satisfaction**: Approval vs rejection rates
- **Edit Frequency**: How often drafts require modification
- **Feedback Velocity**: Time from generation to human review

---

## ğŸ”® Advanced Features

### Document Intelligence
- **Smart Client Matching**: AI-powered client folder identification
- **Contextual Document Selection**: Prioritizes Final Briefs and latest versions
- **Content Integration**: Seamlessly incorporates client context into responses
- **Multi-format Support**: Handles various document types and structures

### Strategic Rejection Handling
- **Rejection Analysis**: Identifies specific rejection reasons and patterns
- **Challenge Angle Generation**: Creates persuasive counter-arguments
- **Client Expertise Leveraging**: Uses stored client information for credibility
- **Follow-up Strategy**: Generates strategic multi-touch sequences

### Real-Time Monitoring
- **Live Dashboard**: Real-time performance visualization
- **Alert System**: Configurable notifications for performance thresholds
- **Error Tracking**: Comprehensive logging and error analysis
- **Quality Assurance**: Automated quality checks and validation

---

## ğŸš€ Replit Deployment - FULLY AUTOMATED

### ğŸ¯ Zero-Configuration Deployment

BookingAssistant is **production-ready for Replit** with **fully automated email processing** that runs continuously without any manual intervention.

#### Step 1: Fork to Replit

1. Go to [replit.com](https://replit.com)
2. Click **"Create Repl"** â†’ **"Import from GitHub"**
3. Enter your repository URL: `https://github.com/your-username/BookingAssistant`
4. Name your Repl: `BookingAssistant`

#### Step 2: Configure Environment Variables

In your Replit **Secrets** tab (ğŸ”’), add these variables:

```bash
# Required: Database
PGDATABASE=neondb
PGUSER=neondb_owner  
PGPASSWORD=your_neon_password
PGHOST=your-neon-host.aws.neon.tech
PGPORT=5432

# Required: AI Processing
OPENAI_API_KEY=your_openai_api_key
ASTRA_DB_APPLICATION_TOKEN=your_astra_token
ASTRA_DB_API_ENDPOINT=your_astra_endpoint

# Required: Email Service - Nylas
NYLAS_API_KEY=your_nylas_api_key
NYLAS_GRANT_ID=your_nylas_grant_id
NYLAS_API_URI=https://api.us.nylas.com

# Required: Google Drive
GDRIVE_CLIENT_ROOT_FOLDER_ID=your_google_drive_folder_id
GOOGLE_APPLICATION_CREDENTIALS=src/service-account-key.json

# Required: Slack Integration
SLACK_WEBHOOK_URL=your_slack_webhook_url
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token

# Optional: CRM Integration
ATTIO_API_KEY=your_attio_api_key

# Production Settings
TESTING_MODE=false
```

#### Step 3: Upload Service Account Key

1. Upload your `service-account-key.json` file to the Replit root directory
2. Ensure the filename matches your `GMAIL_SERVICE_ACCOUNT_FILE` secret

#### Step 4: Start the FULLY AUTOMATED System

Click **"Run"** in Replit! The system will automatically:

âœ… **Auto-Database Setup**: Creates complete schema and loads prompts  
âœ… **Auto-Email Processing**: Starts continuous email monitoring (every 60 seconds)  
âœ… **Auto-Slack Integration**: Sends notifications for human review  
âœ… **Auto-Quality Tracking**: Records metrics and performance data  
âœ… **Auto-Gmail Drafts**: Creates drafts after human approval  

**Expected startup output**:
```
================================================================================
ğŸš€ BOOKING ASSISTANT - FULLY AUTOMATED UNIFIED DEPLOYMENT
================================================================================
ğŸ“§ EMAIL PROCESSING (AUTOMATED):
   â€¢ âœ… Continuous Processing: AUTOMATICALLY ACTIVE
   â€¢ ğŸ“ Manual Trigger: POST https://your-repl-name.replit.app/process_emails
   â€¢ ğŸ”„ Status Check: GET https://your-repl-name.replit.app/email_polling_status
   â€¢ â¸ï¸  Stop Processing: POST https://your-repl-name.replit.app/stop_email_polling

ğŸ¯ FULLY AUTOMATED WORKFLOW:
   ğŸ“§ Fetch Emails â†’ ğŸ¤– AI Processing â†’ ğŸ“ Draft Creation â†’ 
   ğŸ’¬ Slack Notification â†’ ğŸ‘¥ Human Review â†’ ğŸ“Š Metrics Tracking
================================================================================
ğŸš€ Starting automatic email processing...
âœ… Automatic email processing started - checking every 60 seconds
ğŸ“§ Found 5 unread emails to process
ğŸ”„ Processing email from client@example.com: Meeting Request...
âœ… Successfully processed email from client@example.com
â° Next email check in 60 seconds...
```

#### Step 5: Access Your AUTOMATED System

**Your system is now FULLY AUTOMATED!** Access the interfaces:

- **ğŸ  Dashboard**: `https://your-repl-name--your-username.repl.co/`
- **ğŸ“Š Email Status**: `https://your-repl-name--your-username.repl.co/email_polling_status`
- **ğŸ“š API Docs**: `https://your-repl-name--your-username.repl.co/docs`
- **ğŸ”„ Health Check**: `https://your-repl-name--your-username.repl.co/health`

### ğŸ¤– ZERO-MAINTENANCE OPERATION

Once deployed, your system operates **completely automatically**:

#### âœ… **What Happens Automatically**

1. **ğŸ“§ Email Monitoring**: Checks Gmail + Maildoso every 60 seconds
2. **ğŸ¤– AI Processing**: Classifies emails and generates responses
3. **ğŸ“ Document Retrieval**: Finds relevant client documents from Google Drive  
4. **âœï¸ Draft Creation**: Generates contextual email responses
5. **ğŸ’¬ Slack Notifications**: Sends interactive messages for human review
6. **ğŸ“Š Metrics Tracking**: Records all performance data in database
7. **ğŸ”„ Continuous Loop**: Repeats automatically forever

#### ğŸ›ï¸ **Management & Control**

**Check Processing Status:**
```bash
curl https://your-repl-name--your-username.repl.co/email_polling_status
```

**Temporarily Stop Processing:**
```bash
curl -X POST https://your-repl-name--your-username.repl.co/stop_email_polling
```

**Restart Processing:**
```bash
curl -X POST https://your-repl-name--your-username.repl.co/start_email_polling
```

**Manual Email Processing:**
```bash
curl -X POST https://your-repl-name--your-username.repl.co/process_emails
```

#### ğŸ“Š **Only Manual Task: Prompt Management**

The **only thing you need to manage manually** is editing prompts via the dashboard:

1. Go to your dashboard: `https://your-repl-name--your-username.repl.co/`
2. Navigate to **Prompt Management** section  
3. Edit prompts to improve AI responses
4. System automatically uses updated prompts

**Everything else runs automatically 24/7!**

### ğŸ”— Configure Slack Integration

Update your Slack App settings with your Replit URLs:

1. **Interactive Components**: `https://your-repl-name--your-username.repl.co/slack/interactions`
2. **Event Subscriptions**: `https://your-repl-name--your-username.repl.co/slack/events`
3. **Webhook URL**: Use your Slack webhook URL in secrets

### ğŸ“Š Replit Service Architecture

```
https://your-repl-name--your-username.repl.co/
â”œâ”€â”€ /                          # Dashboard homepage  
â”œâ”€â”€ /dashboard                 # Analytics dashboard
â”œâ”€â”€ /api/*                     # Analytics APIs
â”œâ”€â”€ /slack/interactions        # Slack button handling
â”œâ”€â”€ /start_agent_v2           # Email processing endpoint
â”œâ”€â”€ /health                   # System health check
â””â”€â”€ /docs                     # API documentation
```

### âš¡ Production Features

- **Always-On**: Upgrade to Hacker plan ($7/month) for 24/7 operation
- **Auto-Scaling**: Handles traffic spikes automatically  
- **Monitoring**: Built-in health checks and performance tracking
- **Security**: Environment-based secrets management

### ğŸ§ª Test Your Deployment

Once your Replit is running, test the system:

#### 1. Health Check
Visit: `https://your-repl-name--your-username.repl.co/health`

Expected response:
```json
{
  "status": "healthy",
  "services": {
    "dashboard": true,
    "metrics": true,
    "slack_feedback": true
  },
  "database": {
    "connected": true
  }
}
```

#### 2. Process Test Email

Send a test email via the API:
```bash
curl -X POST "https://your-repl-name--your-username.repl.co/start_agent_v2" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "Hi! We are interested in having our CEO as a guest on your podcast. Could you send us more info about the process?",
    "subject": "Podcast Guest Request",
    "sender_name": "Jane Smith",
    "sender_email": "jane.smith@techstartup.com"
  }'
```

#### 3. View Dashboard

Access the analytics dashboard:
`https://your-repl-name--your-username.repl.co/dashboard`

### ğŸ”§ Replit-Specific Tips

- **Keep Alive**: Visit your URL periodically or upgrade to Hacker plan
- **Logs**: Check console output in Replit for debugging
- **Updates**: Push to GitHub and Replit will auto-sync
- **Backup**: Export your environment variables regularly

### ğŸš¨ Automated System Troubleshooting

#### Quick Health Checks

**âœ… Check if email processing is running:**
```bash
curl https://your-repl-name--your-username.repl.co/email_polling_status
# Expected: {"status": "active", "active": true, "thread_alive": true}
```

**âœ… Check system health:**
```bash
curl https://your-repl-name--your-username.repl.co/health
# Should show all services as "true"
```

#### Common Issues & Solutions

**âŒ "Email processing stopped"**
```bash
# Restart email processing
curl -X POST https://your-repl-name--your-username.repl.co/start_email_polling

# Check logs in Replit console for error details
```

**âŒ "Service won't start"**
```bash
# Check if all required secrets are set
python -c "import os; required=['PGHOST', 'OPENAI_API_KEY', 'ASTRA_DB_APPLICATION_TOKEN', 'ASTRA_DB_API_ENDPOINT', 'GMAIL_SERVICE_ACCOUNT_FILE', 'SLACK_WEBHOOK_URL']; missing=[v for v in required if not os.getenv(v)]; print('Missing vars:', missing if missing else 'None - all set!')"

# Test database connection
python test_neon_connection.py

# Run complete database setup  
python setup_complete_database.py
```

**âŒ "No emails being processed"**
- Check Gmail service account permissions
- Verify Maildoso IMAP credentials in Secrets
- Look for "Fetched and filtered X new emails" in console logs
- Ensure emails exist and meet spam filter criteria

**âŒ "Database connection failed"**
- Verify your Neon PostgreSQL credentials in Secrets
- Check that your Neon database is not paused/sleeping
- Run database setup: `python setup_complete_database.py`

**âŒ "Slack interactions not working"**
- Update Slack app URLs to your Replit domain
- Verify `SLACK_WEBHOOK_URL` in Secrets
- Test with: `curl https://your-repl.repl.co/health`

**âŒ "Gmail integration failing"**
- Ensure `service-account-key.json` is uploaded to root directory
- Verify the filename matches `GMAIL_SERVICE_ACCOUNT_FILE` secret
- Check Google API credentials are enabled

**ğŸ’¡ Performance Optimization**
- Enable "Always On" for production use (recommended for 24/7 operation)
- Monitor memory usage in Replit console
- Use connection pooling (automatically enabled)
- Check processing times in dashboard analytics

### ğŸ“‹ Environment Variables Quick Reference

For a complete environment template, see [`.env.replit.example`](.env.replit.example)

| Variable | Required | Description |
|----------|----------|-------------|
| `PGHOST` | âœ… | Neon PostgreSQL host |
| `PGDATABASE` | âœ… | Database name (usually "neondb") |
| `PGUSER` | âœ… | Database username |
| `PGPASSWORD` | âœ… | Database password |
| `OPENAI_API_KEY` | âœ… | OpenAI API key for LLM processing |
| `ASTRA_DB_APPLICATION_TOKEN` | âœ… | AstraDB token for vector search |
| `ASTRA_DB_API_ENDPOINT` | âœ… | AstraDB endpoint URL |
| `ASTRA_DB_KEYSPACE` | âšª | AstraDB keyspace (default: "default_keyspace") |
| `ASTRA_DB_COLLECTION` | âšª | AstraDB collection (default: "email_threads") |
| `GMAIL_SERVICE_ACCOUNT_FILE` | âœ… | Path to Gmail service account JSON |
| `GMAIL_TARGET_EMAIL` | âœ… | Target Gmail address |
| `GDRIVE_CLIENT_ROOT_FOLDER_ID` | âœ… | Google Drive root folder ID |
| `SLACK_WEBHOOK_URL` | âšª | Slack webhook for notifications |
| `SLACK_BOT_TOKEN` | âšª | Slack bot token |
| `ATTIO_API_KEY` | âšª | Attio CRM integration |
| `TESTING_MODE` | âšª | Set to "false" for production |

---

## ğŸš€ Alternative Deployment

### Local Development

For local development or custom hosting:

---

## ğŸ“ Support & Troubleshooting

### Common Issues

**Database Connection Failed**
```bash
# Test connection
python test_neon_connection.py

# Check environment variables
python -c "import os; print('DB Host:', os.getenv('PGHOST'))"
```

**Slack Interactions Not Working**
- Verify ngrok URL in Slack app settings
- Check SLACK_WEBHOOK_URL environment variable
- Ensure Interactive Components are enabled

**No Data in Dashboard**
- Process some emails first with the main assistant
- Verify database schema with `setup_complete_database.py`
- Check metrics service connection in startup logs

### Health Checks

- **Dashboard**: http://localhost:8080/health
- **Slack Endpoint**: http://localhost:8080/slack/interactions
- **API Documentation**: http://localhost:8080/docs

---

## ğŸ‰ Development Status

### âœ… Completed Features - PRODUCTION READY

- **âœ… FULLY AUTOMATED SYSTEM**: Zero-maintenance operation with continuous email processing
- **âœ… Core Pipeline**: LangGraph workflow with conditional routing
- **âœ… Email Processing**: Nylas integration with service account auth + automated polling
- **âœ… Document Intelligence**: Google Drive integration with smart client matching
- **âœ… Vector Search**: AstraDB integration for email thread similarity
- **âœ… Draft Generation**: Contextual responses with template adherence
- **âœ… Slack Integration**: Interactive messages with quality feedback
- **âœ… Performance Tracking**: Three-phase monitoring system with real-time metrics
- **âœ… Real-Time Dashboard**: Comprehensive analytics and visualization
- **âœ… Human Feedback**: Quality rating and approval workflow
- **âœ… Database Integration**: Neon PostgreSQL with auto-schema setup
- **âœ… Automated Deployment**: One-click Replit deployment with zero configuration
- **âœ… Health Monitoring**: Comprehensive system health checks and status endpoints
- **âœ… Error Recovery**: Automatic retry and error handling mechanisms
- **âœ… Testing Framework**: Comprehensive test suite and validation

### ğŸš€ **DEPLOYMENT STATUS: PRODUCTION READY**

**The system is now FULLY AUTOMATED and ready for production use:**

âœ… **Zero Manual Intervention Required**  
âœ… **24/7 Continuous Operation**  
âœ… **Auto-Recovery from Errors**  
âœ… **Real-Time Performance Monitoring**  
âœ… **Seamless Human-AI Collaboration**  
âœ… **Complete Database Auto-Setup**  
âœ… **Production-Grade Error Handling**  

### ğŸ”® Future Enhancements

- **A/B Testing Framework**: Compare prompt variations and model performance
- **Advanced Analytics**: Predictive insights and quality recommendations
- **Multi-language Support**: International email processing capabilities
- **Custom Workflows**: Configurable processing pipelines for different use cases
- **API Rate Limiting**: Enhanced production-ready features
- **Automated Learning**: Feedback-driven prompt optimization
- **Mobile Dashboard**: Mobile-optimized interface for monitoring
- **Multi-tenant Support**: Support for multiple organizations

---

## ğŸ¯ **SYSTEM IS READY FOR PRODUCTION DEPLOYMENT**

**ğŸš€ The BookingAssistant is now a fully automated, production-ready AI email processing system with comprehensive monitoring, analytics, and human oversight capabilities that operates 24/7 without manual intervention.**

### ğŸ“Š **What You Get Out of the Box:**

1. **ğŸ¤– Intelligent Email Processing**: AI-powered classification and response generation
2. **ğŸ“§ Multi-Source Email Integration**: Nylas with automatic polling
3. **ğŸ“ Smart Document Retrieval**: Google Drive integration with context awareness
4. **ğŸ’¬ Human-in-the-Loop**: Slack integration for quality control and approval
5. **ğŸ“Š Real-Time Analytics**: Comprehensive performance dashboard and metrics
6. **ğŸ”„ Continuous Operation**: Fully automated 24/7 processing with error recovery
7. **ğŸ›ï¸ Easy Management**: Simple prompt editing for AI improvement
8. **ğŸ”§ Production Monitoring**: Health checks, status endpoints, and logging

**Deploy once, run forever! ğŸš€**
